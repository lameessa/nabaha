{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0H6cIiryTfxdhkJmkKrrj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lameessa/nabaha/blob/main/Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nabaha | Ù†Ø¨Ø§Ù‡Ø©"
      ],
      "metadata": {
        "id": "7VQvWpmOa1Wu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install all dependencies\n",
        "!apt-get install -y ffmpeg\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "!pip install -q fastapi uvicorn sentence-transformers joblib pyngrok scikit-learn pydantic requests\n",
        "\n",
        "# Imports\n",
        "import uvicorn\n",
        "from fastapi import FastAPI, File, UploadFile\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from pydantic import BaseModel\n",
        "import joblib\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pyngrok import ngrok\n",
        "import nest_asyncio\n",
        "import threading\n",
        "import tempfile\n",
        "import whisper\n",
        "import requests\n",
        "\n",
        "# Load models\n",
        "encoder = SentenceTransformer(\"asafaya/bert-base-arabic\")\n",
        "clf = joblib.load(\"vishing_classifier.pkl\")\n",
        "whisper_model = whisper.load_model(\"large\")\n",
        "\n",
        "# Prediction logic for text\n",
        "def process_text_message(text):\n",
        "    features = encoder.encode([text])\n",
        "    preds = clf.predict(features)[0]\n",
        "    probs = clf.predict_proba(features)\n",
        "    labels = ['is_urgent', 'used_threat', 'good_offers', 'request_money_transfer',\n",
        "              'request_personal_info', 'request_banking_info', 'request_passwords',\n",
        "              'request_code']\n",
        "    predicted_labels = [labels[i] for i, val in enumerate(preds) if val == 1]\n",
        "    confidence = float(np.max(probs[int(np.argmax(preds))]))\n",
        "    return {\n",
        "        \"text\": text,\n",
        "        \"prediction\": \", \".join(predicted_labels) or \"Normal Call\",\n",
        "        \"confidence\": round(confidence * 100, 2)\n",
        "    }\n",
        "\n",
        "# FastAPI app\n",
        "app = FastAPI()\n",
        "\n",
        "# Enable CORS\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "# Text route\n",
        "class TextInput(BaseModel):\n",
        "    message: str\n",
        "\n",
        "@app.post(\"/analyze-text\")\n",
        "async def analyze_text(data: TextInput):\n",
        "    return process_text_message(data.message)\n",
        "\n",
        "# Audio route\n",
        "@app.post(\"/analyze-audio\")\n",
        "async def analyze_audio(file: UploadFile = File(...)):\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as tmp:\n",
        "        tmp.write(await file.read())\n",
        "        tmp_path = tmp.name\n",
        "\n",
        "    # Transcribe using Whisper\n",
        "    result = whisper_model.transcribe(tmp_path, language=\"ar\")\n",
        "    transcribed = result[\"text\"]\n",
        "\n",
        "    # Classify\n",
        "    output = process_text_message(transcribed)\n",
        "    output[\"transcribed_text\"] = transcribed\n",
        "    return output\n",
        "\n",
        "# Start server\n",
        "def run():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "# Setup ngrok\n",
        "ngrok.set_auth_token(\"30NIZIEVqq6WXulqPboiYJAIT0O_zcbk3TQ8SaBSivpL5wgM\")  # Replace with your token\n",
        "public_url = ngrok.connect(8000)\n",
        "print(f\"Public URL is ready: {public_url}\")\n",
        "print(f\"Text API: {public_url}/analyze-text\")\n",
        "print(f\"Audio API: {public_url}/analyze-audio\")\n",
        "\n",
        "# Run server in background\n",
        "nest_asyncio.apply()\n",
        "threading.Thread(target=run).start()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z79ICs5mz0EG",
        "outputId": "a156bfc3-5276-4066-b480-1b8fbeff0781"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name asafaya/bert-base-arabic. Creating a new one with mean pooling.\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.88G/2.88G [00:51<00:00, 59.4MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Public URL is ready: NgrokTunnel: \"https://c0fef0dd53ca.ngrok-free.app\" -> \"http://localhost:8000\"\n",
            "ðŸ”¤ Text API: NgrokTunnel: \"https://c0fef0dd53ca.ngrok-free.app\" -> \"http://localhost:8000\"/analyze-text\n",
            "ðŸŽ§ Audio API: NgrokTunnel: \"https://c0fef0dd53ca.ngrok-free.app\" -> \"http://localhost:8000\"/analyze-audio\n"
          ]
        }
      ]
    }
  ]
}